{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a4c502",
   "metadata": {},
   "source": [
    "# Engaging Complexity: Introduction to Information Theory\n",
    "\n",
    "<table style=\"background-color: white;\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"binary_symmetric.png\" alt=\"binary symmetric channel\" style=\"width: 80%;\"/>\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"Shannon.jpeg\" alt=\"Claude Shannon\" style=\"width: 120%;\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a989897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/james/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/james/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/james/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "import string\n",
    "punct = list(string.punctuation)\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from math import comb\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5becd",
   "metadata": {},
   "source": [
    "# Topic 1: Probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6482722",
   "metadata": {},
   "source": [
    "## 1. What is a probability distribution?\n",
    "\n",
    "A probability distribution is a representation of how likely it is that a variable can take a particular value, for all possible values that the variable can take. There are two types of probability distribution:\n",
    "\n",
    "* A discrete probability distribution is defined in a variable that can take a finite number of possible states\n",
    "* A continuous probability distribution is defined an a variable that can take an infinte number of possible states.\n",
    "\n",
    "A probability can take a value between 0 and 1 inclusive. A value of 0 means that it is impossible for a variable to take that state; a value of 1 means that taking that state is guaranteed. Because a probability distribution is defined across all possible states of a variable, its values must sum to 1 (i.e. it is guaranteed that the system will be in <i>some</i> state)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d4232",
   "metadata": {},
   "source": [
    "### Example 1: A discrete probability distribution\n",
    "\n",
    "<img src=\"NUTS.png\" alt=\"UK NUTS regions\" style=\"width: 40%;\"/>\n",
    "\n",
    "Let's imagine we're interested in picking a random resident of the UK. There are only a finite number of regions they can be from. Once we know the population of each region, we can work out the probability that they are resident in that region by dividing by the regional population by the total UK population:\n",
    "\n",
    "$$P(resident\\;in\\;region) = \\frac{regional\\;population}{UK\\;population}$$\n",
    "\n",
    "According to the Office of National Statistics, the UK population is 67,025,542. Given regional populations, this gives the following distribution:\n",
    "\n",
    "\n",
    "| Region | Population | Probability |\n",
    "|:---------|:--------:|:--------:|\n",
    "| Scotland   |  5463992   | 0.081|\n",
    "| North East  |  2673468   |  0.039|\n",
    "|  North West  |  7355476   | 0.109|\n",
    "|  Yorkshire and<br>the Humber  | 5517920  | 0.082 |\n",
    "|  Northern<br>Ireland | 1898785 | 0.028 |\n",
    "|  East<br>Midlands | 4861236 | 0.072 |\n",
    "|  West<br>Midlands | 5962551| 0.088 |\n",
    "|  East of<br>England | 6259318| 0.093 |\n",
    "|  London| 9004875| 0.134 |\n",
    "|  South East| 9212113| 0.137 |\n",
    "|  South West | 5660791|0.084 |\n",
    "|  Wales | 3155017|0.047 |\n",
    "\n",
    "Charting this on a barplot gives us a graphical representation of our discrete probability distribution:\n",
    "\n",
    "<img src=\"populations_.png\" alt=\"chart\" width=\"600\" height=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733b5c6",
   "metadata": {},
   "source": [
    "## Example 2: A continuous probability distribution\n",
    "\n",
    "Let's imagine we're interested in the probability of a random person being a partcular height. While there are physical limitations on how tall a human being can be (the record is 272cm), every human has been every value of height smaller than their current height. This means that height varies continuously. Height also forms a normal distribution, which means that extreme values are uncommon.\n",
    "\n",
    "<img src=\"Height.png\" alt=\"height\" style=\"width: 60%;\"/>\n",
    "\n",
    "Though we will be dealing with discrete distributions, are are two features of continuous probability distributions you should probably be aware of:\n",
    "\n",
    "* Where the sum of probabilities in a discrete distribution is 1, the area under the curve in a continuus distributions sums to 1.\n",
    "* Because a continuous distribution technically contains an infinite number of values, the probability of any one exact value occurring is 0. Instead, probability is defined in a range of values––see below.\n",
    "\n",
    "<img src=\"Height_strip.png\" alt=\"height\" style=\"width: 60%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e70dc3",
   "metadata": {},
   "source": [
    "## 2. Joint probability distributions\n",
    "\n",
    "A joint probability is defined across the states of two variables. It registers the probability of every possible pair of states of the two variables occurring. Let's explore with an example.\n",
    "\n",
    "Every resident of the UK lives in a specfic region; we have already worked out the probability of a random person living in each of these regions. However, every UK resident also has an ethnicity. Census data records these as follows:\n",
    "\n",
    "| Ethnicity | Population | Probability |\n",
    "|:---------|:--------:|:--------:|\n",
    "| Asian   |  5026915.6  | 0.075|\n",
    "| Black  |  2211842.8   |  0.033|\n",
    "|  Mixed  |  1474561.9   | 0.022|\n",
    "|  Other  | 670255.4  | 0.01 |\n",
    "|  White | 57641966.1 | 0.86 |\n",
    "\n",
    "\n",
    "A joint probability distribution across region of residence ($X$) and ethnicity ($Y$) would list the probility of random person being of a specific ethnicity and living in a specific region, for all values of region and ethnicity. How could we calculate this? \n",
    "\n",
    "This is done using the law of $AND$, or the multiplication rule. Namely, for any two independent events, the probability of their joint occurence is the product of their individual probabilities. (The law of $OR$ states that the probability of one OR another independent events occurring is ascertained by adding their probabilities.)\n",
    "\n",
    "Let's take an example: What's the probability of residing in the North West and being of Asian ethnicity?\n",
    "\n",
    "$$P(X=North\\;West)=0.109$$\n",
    "$$P(Y=Asian)=0.075$$\n",
    "$$P(Y=North\\;West,\\;Y=Asian)=0.109\\times{0.075}=0.008175$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ea1f6",
   "metadata": {},
   "source": [
    "### Let's create a dataframe that gives us the joint probabilities for all pairs of values for region and ethnicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64aacbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "UK_regions = {'Scotland': 5463992, 'North East': 2673468, 'North West': 7355476, 'Yorkshire and the Humber': 5517920, \\\n",
    "              'Northern Ireland': 1898785, 'East Midlands': 4861236, 'West Midlands': 5962551, \\\n",
    "              'East of England' : 6259318, 'London': 9004875, 'South East': 9212113, 'South West': 5660791, \\\n",
    "              'Wales': 3155017}\n",
    "total_pop = sum([i for i in UK_regions.values()])\n",
    "region_prob = [i/total_pop for i in UK_regions.values()]\n",
    "\n",
    "UK_ethnicity = {'Asian': 0.075, 'Black': 0.033, 'Mixed': 0.022, 'Other': 0.01, 'White': 0.86}\n",
    "ethnic_prob = list(UK_ethnicity.values())\n",
    "\n",
    "\n",
    "table = [[] for x in range(len(UK_regions.keys()))]\n",
    "\n",
    "for i in range(len(UK_regions.keys())):\n",
    "    for j in ethnic_prob:\n",
    "        table[i].append(region_prob[i]*j)\n",
    "    \n",
    "\n",
    "joint_distribution = pd.DataFrame(table, columns = UK_ethnicity.keys(), index = UK_regions.keys())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95147aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joint_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "263911b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asian    0.075\n",
       "Black    0.033\n",
       "Mixed    0.022\n",
       "Other    0.010\n",
       "White    0.860\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_distribution.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce2a0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scotland                    0.081521\n",
       "North East                  0.039887\n",
       "North West                  0.109741\n",
       "Yorkshire and the Humber    0.082326\n",
       "Northern Ireland            0.028329\n",
       "East Midlands               0.072528\n",
       "West Midlands               0.088959\n",
       "East of England             0.093387\n",
       "London                      0.134350\n",
       "South East                  0.137442\n",
       "South West                  0.084457\n",
       "Wales                       0.047072\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_distribution.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409a970",
   "metadata": {},
   "source": [
    "## In-class exercise\n",
    "\n",
    "1. What day of the week were you born on? [Go here to find out](https://www.timeanddate.com/date/weekday.html)\n",
    "2. Is the day of the month you were born in an odd or even number?\n",
    "\n",
    "Now, let's create a dataframe with these values for the whole class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733b1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = {'Monday': 2, 'Tuesday': 5, 'Wednesday': 6, 'Thursday': 3, 'Friday': 3, 'Saturday': 2, 'Sunday': 5}\n",
    "oddness = {'Odd': 16, 'Even': 10}\n",
    "\n",
    "total = sum([i for i in days.values()])\n",
    "days_prob = [i/total for i in days.values()]\n",
    "oddness_prob = [i/total for i in oddness.values()]\n",
    "\n",
    "table = [[] for x in range(len(days.keys()))]\n",
    "\n",
    "for i in range(len(days.keys())):\n",
    "    for j in oddness_prob:\n",
    "        table[i].append(days_prob[i]*j)\n",
    "    \n",
    "\n",
    "class_distribution = pd.DataFrame(table, columns = oddness.keys(), index = days.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182642b",
   "metadata": {},
   "source": [
    "#### Some questions:\n",
    "\n",
    "1. What is the probability of a person having an odd birthday on a weekend?\n",
    "2. Select two people at random. What's the probability they both share a non-weekend birthday OR an odd birthday?\n",
    "3. Select two people at random. What's the probability they both share a the same day of the week as a birthday?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090191e",
   "metadata": {},
   "source": [
    "# Topic 2: Shannon entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9695b5",
   "metadata": {},
   "source": [
    "### Surprise\n",
    "\n",
    "What is entropy? There are several kinds, but the two most common are <b>thermodynamic entropy</b> and <b>information-theoretic entropy</b>. Thermyodynamic entropy is a <b>measure of disorder</b> in a system; information-theoretic entropy (called Shannon entropy) is a <b>measure of unpredicatbility</b> in a system. Though both concepts are related, we are here interested in Shannon entropy. \n",
    "\n",
    "The first step in understanding entropy comes with defining the notion of <b>surprise</b> (sometimes called surprisal, information, or self-information). When is an event surprising? When it's unlikely but happens anyway. Therefore, surprise is inveresely proportional to probability: high probability events have low surprise (we expect them to occur) while low probability events have high surprise (we don't expect them to occur).\n",
    "\n",
    "Let's take an example. What would surprise us most if it fell from the sky––frogs, ash, snow, or rain?\n",
    "\n",
    "<img src=\"frogs.png\" alt=\"frogs\" style=\"width: 60%;\"/>\n",
    "\n",
    "The answer, obviously, is frogs––but how can we quantify this? We need a function that, in the $0$ to $1$ range, makes small probabilities large and large probabilities small. Do we have such a function?\n",
    "\n",
    "Yes we do! The negative of the logarithmic function does exactly this. That is:\n",
    "\n",
    "$$S = -\\log_{2}(p)$$\n",
    "\n",
    "If we define surprise in this way and plot the results, we can quickly see why it works:\n",
    "\n",
    "<img src=\"surprise.png\" alt=\"surprise\" style=\"width: 60%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e70d1",
   "metadata": {},
   "source": [
    "### Expected value\n",
    "\n",
    "The second step in understanding entropy comes with the idea of <b>expected value</b>. This captures the long-term output of a system. It is calculated by mutiplying the probability of system's state by the output of the system's state, and adding the results for all the states. \n",
    "\n",
    "Imagine my system, $X$ is a biased coin, with $P(heads) = 0.75$ and $P(tails) = 0.25$. Now, further suppose that I get £25 every time I get a head, and £35 every time I get a tail. My expected value for $X$, $E[X]$ is given by:\n",
    "\n",
    "$$E[X] = (0.75\\times{25})+(0.25\\times{35})= £27.5$$\n",
    "\n",
    "That is, the long-run average of my takings will trend towards £27.5. We can see this by simulating 1,000 trials:\n",
    "\n",
    "<img src=\"expected_value_.png\" alt=\"ev\" style=\"width: 60%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071b99f",
   "metadata": {},
   "source": [
    "### Definition: Entropy is the expected value of surprise\n",
    "\n",
    "We can now attempt to define Shannon entropy, often denoted by $H$. Entropy is a measure of unpredictability and therefore of surprise; we have already seen how $-log_{2}(p)$ quantifies surprise for a single event. In entropy, we are interested in the surprise associated with all the states (i.e. events) of a specfic system. In other words, <b>entropy is the expected value of surprise</b>. To calculate it, we multiply the surprise of a state by its probability of occurring, and add up the results for every state of the system. \n",
    "\n",
    "This is the formula for entropy, where $H$ is the entropy measure and $X$ is a discrete probability distribution over $n$ states of a system:\n",
    "\n",
    "$$X = (x_1, x_2, x_3, ... x_n)$$\n",
    "\n",
    "$$H(X) = -\\sum_{x \\in X} p(x)\\log_{2} p(x)$$\n",
    "\n",
    "The $\\sum_{x \\in X}$ notation here simply means \"add up the results for every value of $x$ in $X$\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84dbbb9",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "<img src=\"urn.png\" alt=\"ev\" style=\"width: 30%;\"/>\n",
    "\n",
    "\n",
    "What does this look like in practice? Let's take an example. An urn contains 7 red balls and 3 blue balls. What is the entropy of this system $X$? The answer comes with recognising that it defines a probability distribution across colours:\n",
    "\n",
    "$P(X=red):\\frac{7}{10}$\n",
    "\n",
    "$P(X=blue):\\frac{3}{10}$\n",
    "\n",
    "$$H(X) = -\\begin{bmatrix}{\\frac{7}{10}\\times \\log_{2}(\\frac{7}{10}) + \\frac{3}{10}\\times \\log_{2}(\\frac{3}{10})}\\end{bmatrix}$$\n",
    "\n",
    "$$H(X) = -[-0.5210896782498619 - 0.3602012209808308]$$\n",
    "\n",
    "$$H(X) = 0.8812908992306927\\;bits$$\n",
    "\n",
    "Compare with an urn that contains 5 red balls and 5 blue balls:\n",
    "\n",
    "$$H(X) = -\\begin{bmatrix}{\\frac{5}{10}\\times \\log_{2}(\\frac{5}{10}) + \\frac{5}{10}\\times \\log_{2}(\\frac{5}{10})}\\end{bmatrix}$$\n",
    "\n",
    "$$H(X) = -[-0.5 - 0.5]$$\n",
    "\n",
    "$$H(X) = 1\\;bits$$\n",
    "\n",
    "Because the urn with equal numbers of red and blue balls is harder to predict, it has higher entropy than the system with more red than blue balls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a874a",
   "metadata": {},
   "source": [
    "### Calculating entropy using `scipy`\n",
    "\n",
    "Usefully, python allows us to calculate entropy easily using the `scipy` library. [Find the docs here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ee84b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of probability distribution of residing in UK region in bits: 2.4038891997141607\n",
      "Entropy of probability distribution of belonging to ethnicity in bits: 0.5665682812818006\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "regions_e = entropy(region_prob)\n",
    "ethnic_e = entropy(ethnic_prob)\n",
    "\n",
    "print(\"Entropy of probability distribution of residing in UK region in bits:\", regions_e)\n",
    "print(\"Entropy of probability distribution of belonging to ethnicity in bits:\", ethnic_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e694505b",
   "metadata": {},
   "source": [
    "# Topic 3: Problem-solving using entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b550090c",
   "metadata": {},
   "source": [
    "### 1. Distinguishing between language and noise\n",
    "\n",
    "One particular value of entropy is in distinguishing between in information containing signal and noise. For a signal to be present, it must be encoded––and encoding implies repetition. Here, we will explore an example of how we might use entropy to do this for written text.\n",
    "\n",
    "1. We we will split two texts––Emily Brontë's <i>Wuthering Heights</i> and William Shakespeare's <i>Collected Works</i>––into their constituent words.\n",
    "2. We will generate 25 texts made up of random strings of characters of characters of random length.\n",
    "3. We will cryptographically hash each word of each text using the SHA-256 algorithm to make them indistinguishable to the human eye.\n",
    "4. We will scramle the list of texts so we don't know where the real and the fake ones are.\n",
    "5. We will measure the entropy of the resulting hashed word frequency distributions to see if we can identify the real texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06e0752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43b77df40a9246f9f108eea17ecdcca30a480c8d0c966cc4040ab8bef838c4ad\n"
     ]
    }
   ],
   "source": [
    "#Import and demo the hashing library\n",
    "\n",
    "import hashlib\n",
    "\n",
    "input_string = \"I am your naughty browsing history\"\n",
    "\n",
    "# Create a SHA-256 hash object\n",
    "hash_object = hashlib.sha256()\n",
    "hash_object.update(input_string.encode())\n",
    "\n",
    "hex_dig = hash_object.hexdigest()\n",
    "\n",
    "print(hex_dig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a8de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open and extract words from our literary texts\n",
    "\n",
    "with open('wuthering_heights.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text = text.encode('ascii', 'ignore')\n",
    "text = text.decode()\n",
    "text = ' '.join(text.splitlines())\n",
    "text = text.lower()\n",
    "words = word_tokenize(text)\n",
    "lemmas_wh = [lemmatizer.lemmatize(i) for i in words]\n",
    "\n",
    "with open('shakespeare_cw.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text = text.encode('ascii', 'ignore')\n",
    "text = text.decode()\n",
    "text = ' '.join(text.splitlines())\n",
    "text = text.lower()\n",
    "words = word_tokenize(text)\n",
    "lemmas_sh = [lemmatizer.lemmatize(i) for i in words]\n",
    "lemmas_sh = lemmas_sh[:len(lemmas_wh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32a05125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate our noisy texts\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "def randoms(n, min_length, max_length):\n",
    "    random_strings = []\n",
    "    for _ in range(n):\n",
    "        length = random.randint(min_length, max_length)\n",
    "        random_str = ''.join(random.choice(string.ascii_lowercase) for _ in range(length))\n",
    "        random_strings.append(random_str)\n",
    "    return random_strings\n",
    "\n",
    "n = len(lemmas_wh)  # Number of strings\n",
    "min_length = 1  # Minimum length of strings\n",
    "max_length = 12  # Maximum length of strings\n",
    "\n",
    "texts = []\n",
    "\n",
    "for i in range(25):\n",
    "    texts.append(randoms(n, min_length, max_length))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bcecb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle and then cryptographically hash all our texts\n",
    "\n",
    "import random\n",
    "all_text = texts + [lemmas_wh] + [lemmas_sh]\n",
    "random.shuffle(all_text)\n",
    "\n",
    "hashes = [[] for i in range(len(all_text))]\n",
    "\n",
    "for i in range(len(all_text)):\n",
    "    for j in all_text[i]:\n",
    "        hash_object = hashlib.sha256()\n",
    "        hash_object.update(j.encode())\n",
    "        hex_dig = hash_object.hexdigest()\n",
    "        hashes[i].append(hex_dig)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7029ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get counts of hashed words and create probability distribution\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "distributions = []\n",
    "\n",
    "for i in hashes:\n",
    "    item_counts = Counter(i)\n",
    "    prob = [j/len(i) for j in item_counts.values()]\n",
    "    distributions.append(prob)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7841a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and plot entropies for each text\n",
    "\n",
    "entropies = [entropy(i, base = 2) for i in distributions]\n",
    "entropies = pd.Series(entropies)\n",
    "\n",
    "sns.barplot(x = entropies.index, y = entropies.values)\n",
    "plt.xlabel('hashed text ID')\n",
    "plt.ylabel('bits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98f0b3",
   "metadata": {},
   "source": [
    "### 2. Joint entropy\n",
    "\n",
    "Just as we can have a joint probability distribution made up of two probability distributions, so too can we have joint entropy. This is given by the formula below, but in practice, we will usually already have the joint distribution worked out in our data.\n",
    "\n",
    "$$X = (x_1, x_2, x_3, ... x_n)$$\n",
    "\n",
    "$$Y = (y_1, y_2, y_3, ... y_n)$$\n",
    "\n",
    "$$H(X) = -\\sum_{y \\in Y}\\sum_{x \\in X} p(x,y)\\log_{2} p(x,y)$$\n",
    "\n",
    "The value of the joint entropy is that it allows us to ascertain if there's a dependency between the variables. If they're independent of each other, then the joint entropy will equal the sum of the individual entropies. If one distribution is dependent on another, the joint entropy will be less than the sum. In general:\n",
    "\n",
    "$$H(X,Y)\\le H(X) + H(Y)$$\n",
    "\n",
    "Let's take an example: the distribution of ages across the regions of the UK. \n",
    "\n",
    "* <b>Question: Are these distributions independent of each other?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_excel(\"pop_age.xlsx\", index_col = 0)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbd0135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pop.sum().sum()\n",
    "joint_df = pop/total\n",
    "\n",
    "prob_regions = [i/total for i in pop.sum(axis =1)]\n",
    "prob_ages = [i/total for i in pop.sum()]\n",
    "\n",
    "joint = pop.values.flatten().tolist()\n",
    "joint = [i/total for i in joint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95016adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "sns.heatmap(joint_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55e2b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_ = joint_df.reset_index()\n",
    "\n",
    "joint_ = joint_.melt(id_vars = ['index'])\n",
    "joint_['variable'] = [int(i[1:]) for i in joint_['variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d541340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = 'variable', y = 'value', hue = 'index', data = joint_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6afcb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_entropy = entropy(prob_regions) + entropy(prob_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583bbdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The entropy of the population distribution by region is\", entropy(prob_regions), \"bits\")\n",
    "print(\"The entropy of the population distribution by age is\", entropy(prob_ages), \"bits\")\n",
    "print(\"The joint entropy is\", entropy(joint), \"bits\")\n",
    "print(\"The difference between the joint entropy and the sum of the individuals is\", sum_entropy- entropy(joint), \"bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10139b3c",
   "metadata": {},
   "source": [
    "$$H(X,Y) < H(X) + H(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6caec",
   "metadata": {},
   "source": [
    "# Topic 3: Measuring model fit\n",
    "\n",
    "> All models are wrong, but some are useful\n",
    ">\n",
    ">\n",
    "> ––<cite>George Box</cite>\n",
    "\n",
    "As a description of likelihood of the states of a system, a probability distribution is a <b>model</b> of that system. As a measure of the unpredictability of a system, so too is the entropy of a system a model of it. It is often the case that we have several models of a system and wish to judge which is the best match. This measured using what are known as [Bregman divergences](https://danmackinlay.name/notebook/bregman_divergences). In our case, we are interested in a specific divergence called the <b>Kullback-Leibler</b> or <i>$D_{KL}$</i> divergence. What is this quantity?\n",
    "\n",
    "Imagine we have true model $P(X)$. That is, $P(X)$ is a proability distribution across $X$, the states of a system. Let's suppose that $P(X)$ is a complicated distribution that it's hard to work with. If we don't need to be exact, then we can use a simpler distribution, $Q(X)$, to approximate $P(X)$. There are lots of situations where this is a useful feature. The question is, how can we measure how good a fit different candidates for $Q(X)$ might be? This is what the <i>KL</i> divergence does. Consider the two scenarios below:\n",
    "\n",
    "<img src=\"KL_.png\" alt=\"KL\" style=\"width: 60%;\"/>\n",
    "\n",
    "Compared to the top panel, the estimating distribution $Q_2{(X)}$ in the bottom panel covers more of $P(X)$ than $Q_1{(X)}$ in the top panel. Thus, for any range of values of $X$, the values of $Q_2{(X)}$ will, on average, be closer to $P(X)$ than $Q_1{(X)}$. How might we quantify this?\n",
    "\n",
    "Let's go back to our definition of entropy as the expected value of surprise. In all cases, $Q(X)$ will be more surprising than $P(X)$. This is because $Q(X)$ will always contain some error; if it was a perfect fit, we wouldn't need to use an estimation. However, the better the fit is, the less surprise $Q(X)$ will add to $P(X)$. We can calculate this by getting the surprise for every value of $X$ under $P$ and under $Q$ and subtracting $P$ from $Q$ to get the excess surprise under $Q$. (Here, $S$ denotes the excess surprise.)\n",
    "\n",
    "$$S(X=x) = [-\\log_{2}Q(x)] - [-\\log_{2}P(x)]$$\n",
    "$$S(X=x) = [-\\log_{2}Q(x) + \\log_{2}P(x)]$$\n",
    "$$S(X=x) = [\\log_{2}P(x) - \\log_{2}Q(x)]$$\n",
    "\n",
    "Multiplying by the true probability of $x$, here given by $P(x)$, then gives us the expected value, $E[S]$:\n",
    "\n",
    "$$E[S(X=x)] = P(x)[\\log_{2}P(x) - \\log_{2}Q(x)]$$\n",
    "\n",
    "Using the laws of logs, we can turn this difference (subtraction) into a quotient (division):\n",
    "\n",
    "$$E[S(X=x)] = P(x)\\log_{2}\\frac{P(x)}{Q(x)}$$\n",
    "\n",
    "The final step comes with getting the expected value of excess surprise, $E[S]$, for all values of $X$. We do this (as with entropy) by summing across all values of $X$:\n",
    "\n",
    "\n",
    "$$D_{KL} = \\sum_{x \\in X}P(x)\\log_{2}\\frac{P(x)}{Q(x)}$$\n",
    "\n",
    "In practice, however, we rarely need to calculate this by hand. The `scipy` `entropy` function gives back the $D_{KL}$ when you pass it two distibutions, where:\n",
    "\n",
    "* Both distributions are the same length\n",
    "* Neither distribution contains a zero value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d903660",
   "metadata": {},
   "source": [
    "### Example 1: Estimating a biased dice\n",
    "\n",
    "Let's imagine we have a biased dice, such that the probability distribution across faces is:\n",
    "\n",
    "$$P = (0.1, 0.2, 0.25, 0.15, 0.2, 0.1)$$\n",
    "\n",
    "Now, we want to make another dice that we can use to mimic the behaviour of this dice. But we have a problem: our biased-dice-making machine is broken, and we can only change the bias on two faces of our new dice. This means our estimating distribution, $Q$, will be of the form:\n",
    "\n",
    "$$Q = (0.16, 0.16, 0.16, 0.16, x, y)$$\n",
    "\n",
    "What values should we give to $x$ and $y$ to get the best $Q$ estimation?  Given that $x$ and $y$ must sum to $\\frac{1}{3}$, we can get the $D_{KL}$ for all values of $p \\le{0.33}$, where $x = p$ and $y = 0.33-p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69af6841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$D_{KL}$')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_probs = [1/6, 1/6, 1/6, 1/6]\n",
    "Q = []\n",
    "P = [0.1, 0.2, 0.25, 0.15, 0.2, 0.1]\n",
    "\n",
    "for i in np.linspace(0.01,0.33,100):\n",
    "    E = fixed_probs.copy()\n",
    "    E.append(i)\n",
    "    E.append(0.33-i)\n",
    "    Q.append(E)\n",
    "\n",
    "KL = [entropy(P,i, base =2) for i in Q]\n",
    "\n",
    "\n",
    "sns.lineplot(x = np.linspace(0.01,0.33,100), y = KL)\n",
    "plt.xlabel('bias')\n",
    "plt.ylabel('$D_{KL}$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3039b7",
   "metadata": {},
   "source": [
    "### Example 2: Estimating the representativeness of a language model\n",
    "\n",
    "Though no corpus of language is definitive, linguists have compiled several large corpora that give a big picture overview of how language is used across all domains of human activity. One of these is the [Fisher corpus](https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/lrec2004-fisher-corpus.pdf), which used around 2,000 hours of recorded phone calls in the USA from the early 2000s to gain word frequency estimates. These were recorded as frequency of word per million word used, and divided by gender. The Fisher corpus thus provides a reliable 'ground truth' for English, at least in its North American variety.\n",
    "\n",
    "Now, imagine that we want to answer a specific question: \n",
    "\n",
    "* <b>Are there gender differences in how emotion words are used on social media, relative to English as a whole?</b>\n",
    "\n",
    "To answer this question, we can compare the distribution of emotion words by gender [in this Twitter dataset](https://www.kaggle.com/datasets/crowdflower/twitter-user-gender-classification) to their distribution in the Fisher Corpus, and use the $D_{KL}$ to quantify the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90775dd2",
   "metadata": {},
   "source": [
    "### 1. Import data and define emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c111f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher = pd.read_csv(\"fisher_corpus.csv\", index_col = 0)\n",
    "twitter = pd.read_csv(\"twitter_gender.csv\", encoding = 'latin-1')\n",
    "\n",
    "emotions = [\n",
    "    'happiness', 'sadness', 'anger', 'fear', 'surprise', \\\n",
    "    'disgust', 'love', 'envy', 'jealousy', 'pride', 'shame', \\\n",
    "    'guilt', 'contentment', 'disappointment', 'hope', 'despair', \\\n",
    "    'curiosity', 'boredom', 'loneliness', 'gratitude', 'excitement', \n",
    "    'anxiety', 'sympathy', 'compassion', 'frustration', 'euphoria',\\\n",
    "    'melancholy', 'nostalgia', 'optimism', 'empathy', 'apathy', \\\n",
    "    'confusion', 'relief', 'indignation', 'admiration', 'amazement', \\\n",
    "    'awe', 'serenity', 'calmness', 'overwhelm', 'eagerness', 'satisfaction', \\\n",
    "    'enthusiasm', 'passion', 'infatuation', 'longing', 'regret', \\\n",
    "    'resentment', 'irritation', 'discontent', 'grief', 'sorrow', \\\n",
    "    'elation', 'glee', 'joy', 'bliss', 'delight', 'pleasure', 'humility', \\\n",
    "    'disdain', 'contempt', 'spite', 'trust', 'distrust', 'skepticism', 'faith', \\\n",
    "    'doubt', 'shock', 'horror', 'terror', 'panic', 'hysteria', 'agony', \\\n",
    "    'ecstasy', 'tranquility', 'peacefulness', 'jubilation', 'triumph', 'defeat', \\\n",
    "    'anticipation', 'yearning', 'remorse', 'acceptance', 'resignation', 'indifference', \\\n",
    "    'apprehension', 'embarrassment', 'tenderness', 'warmth'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b374c",
   "metadata": {},
   "source": [
    "### 2. Process the Twitter data into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5042889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = twitter[['gender', 'text']]\n",
    "\n",
    "lem = []\n",
    "\n",
    "for i in twitter['text']:\n",
    "    words = word_tokenize(i)\n",
    "    lemmas = [lemmatizer.lemmatize(i) for i in words]\n",
    "    lemmas = [i.lower() for i in lemmas if i not in punct and i not in stops]\n",
    "    lem.append([i for i in lemmas])\n",
    "\n",
    "twitter['lemmas'] = lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a19430",
   "metadata": {},
   "source": [
    "### 3. Get the distribution of emotion word use by male and female in the Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1b343197",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words = []\n",
    "female_words = []\n",
    "\n",
    "twitter_m = twitter[twitter['gender'] == 'male']\n",
    "twitter_m = twitter_m[['gender', 'text', 'lemmas']]\n",
    "\n",
    "twitter_f = twitter[twitter['gender'] == 'female']\n",
    "twitter_f = twitter_f[['gender', 'text', 'lemmas']]\n",
    "\n",
    "for i in twitter_m['lemmas']:\n",
    "    for j in i:\n",
    "        male_words.append(j)\n",
    "        \n",
    "for i in twitter_f['lemmas']:\n",
    "    for j in i:\n",
    "        female_words.append(j)\n",
    "        \n",
    "male_freq = Counter(male_words)\n",
    "female_freq = Counter(female_words)\n",
    "\n",
    "male_emotions = [male_freq[i] for i in emotions]\n",
    "female_emotions = [female_freq[i] for i in emotions]\n",
    "\n",
    "# Add small value to prevent zero values\n",
    "\n",
    "epsilon=1e-10\n",
    "\n",
    "m_smoothed = np.array(male_emotions) + epsilon\n",
    "f_smoothed = np.array(female_emotions) + epsilon\n",
    "\n",
    "# Normalizing the distributions\n",
    "m_normalized = m_smoothed / m_smoothed.sum()\n",
    "f_normalized = f_smoothed / f_smoothed.sum()\n",
    "\n",
    "twitter_emo = pd.DataFrame()\n",
    "twitter_emo.index = emotions\n",
    "twitter_emo['male'] = m_normalized\n",
    "twitter_emo['female'] = f_normalized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f596ea0",
   "metadata": {},
   "source": [
    "### 4. Get frequency data for the emotion words in the Fisher corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "553e7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_emo = fisher.loc[emotions]\n",
    "fisher_emo['male'] = [i for i in fisher_emo['male']/fisher_emo['male'].sum()]\n",
    "fisher_emo['female'] = [i for i in fisher_emo['female']/fisher_emo['female'].sum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741da9a1",
   "metadata": {},
   "source": [
    "### 5. Get the $D_{KL}$ for male and female emotion words in Twitter relative to Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b199b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_KL = entropy(fisher_emo['male'], twitter_emo['male'])\n",
    "female_KL = entropy(fisher_emo['female'], twitter_emo['female'])\n",
    "print('The male KL divergence is', male_KL, 'bits')\n",
    "print('The female KL divergence is', female_KL, 'bits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca5e67",
   "metadata": {},
   "source": [
    "### Appendix: Adjusted $D_{KL}$ function to avoid zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cf5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(P, Q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Calculate the KL divergence between two distributions, adding a small constant to handle zeroes.\n",
    "\n",
    "    Parameters:\n",
    "    P (array-like): The first probability distribution.\n",
    "    Q (array-like): The second probability distribution.\n",
    "    epsilon (float): A small constant for smoothing (default is 1e-10).\n",
    "\n",
    "    Returns:\n",
    "    float: The KL divergence between P and Q.\n",
    "    \"\"\"\n",
    "    # Smoothing the distributions\n",
    "    P_smoothed = np.array(P) + epsilon\n",
    "    Q_smoothed = np.array(Q) + epsilon\n",
    "\n",
    "    # Normalizing the distributions\n",
    "    P_normalized = P_smoothed / P_smoothed.sum()\n",
    "    Q_normalized = Q_smoothed / Q_smoothed.sum()\n",
    "\n",
    "    # Calculate KL divergence\n",
    "    return entropy(P_normalized, Q_normalized)\n",
    "\n",
    "kl(_emo['male'], fisher_emo['male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0600e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
